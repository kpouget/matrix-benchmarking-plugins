Name:         ssd-inference-2-0-0
Namespace:    matrix-benchmarking
Priority:     0
Node:         perfdgx2.perf.lab.eng.bos.redhat.com/10.16.30.12
Start Time:   Thu, 21 Apr 2022 14:33:23 +0200
Labels:       controller-uid=702a48b2-48c9-4ca5-9e08-363024eab802
              job-name=ssd-inference-2
              matrix-benchmarking=true
              project=hello
              runai-pod-job-mutated=true
              runai/pod-index=0-0
              user=admin
Annotations:  gpu-fraction: 0.100000
              k8s.v1.cni.cncf.io/network-status:
                [{
                    "name": "openshift-sdn",
                    "interface": "eth0",
                    "ips": [
                        "10.128.1.4"
                    ],
                    "default": true,
                    "dns": {}
                }]
              k8s.v1.cni.cncf.io/networks-status:
                [{
                    "name": "openshift-sdn",
                    "interface": "eth0",
                    "ips": [
                        "10.128.1.4"
                    ],
                    "default": true,
                    "dns": {}
                }]
              openshift.io/scc: runai-jupyter-notebook
              pod-group-name: pg-ssd-inference-2-702a48b2-48c9-4ca5-9e08-363024eab802
              runai-allocated-gpu-memory: 3430
              runai-allocated-gpus: 0.1
              runai-allocated-mig-gpus: 0
              runai-calculated-status: Running
              runai-gpu: 12
              runai-node: perfdgx2.perf.lab.eng.bos.redhat.com
Status:       Running
IP:           10.128.1.4
IPs:
  IP:           10.128.1.4
Controlled By:  RunaiJob/ssd-inference-2
Containers:
  ctr:
    Container ID:  cri-o://3abf9b814b939dcffb6e4d21ede677ddfbfb0aa68ef960dd103afad522ae25a7
    Image:         quay.io/openshift-psap/nvidiadl-ssd-training-benchmark:ssd
    Image ID:      quay.io/openshift-psap/nvidiadl-ssd-training-benchmark@sha256:0177e9f4174b98ed1b79a952b2bdf60be6c0a1d7d534b46e6f34a6012db4e52f
    Port:          <none>
    Host Port:     <none>
    Command:
      bash
      -ceuxo
      pipefail
    Args:
      mkdir /tmp/cfg
      cp -v "$SRC_CONFIG_DIR"/* /tmp/cfg
      sed -i 's|/data/coco2017_tfrecords|'$STORAGE_DIR'/coco2017_tfrecords|' /tmp/cfg/*
      sed -i 's|/checkpoints|'$STORAGE_DIR'/checkpoints|' /tmp/cfg/*
      
      if [[ "inference" == "inference" ]]; then
        count=0
        SECONDS=0 # Bash special var
        while true; do
          bash examples/SSD320_FP16_inference.sh  /tmp/cfg --raport_file=/tmp/summary.json
          count=$(($count + 1))
          echo "INFERENCE_LOOP_COUNT=$count"
          if [[ "$INFERENCE_TIME" ]]; then
            minutes=$((SECONDS/60))
            if [[ "$minutes" -ge "$INFERENCE_TIME" ]]; then
              echo "Inference ran for ${minutes}, bailing out."
              break
            fi
          fi
        done
      else
        RESULTS_DIR=/tmp/results
        mkdir "$RESULTS_DIR"
        bash examples/SSD320_FP16_inference.sh  "$RESULTS_DIR" /tmp/cfg --raport_file=/tmp/summary.json
        cat "${RESULTS_DIR}/train_log" || true
      fi
      
    State:          Running
      Started:      Thu, 21 Apr 2022 14:33:26 +0200
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:     100m
      memory:  10485760
    Environment:
      SRC_CONFIG_DIR:          /workdir/models/research/configs/
      STORAGE_DIR:             /storage
      INFERENCE_TIME:          
      reporterGatewayURL:      runai-prometheus-pushgateway.runai.svc.cluster.local:9091
      REPORTER_GATEWAY_URL:    runai-prometheus-pushgateway.runai.svc.cluster.local:9091
      podUUID:                  (v1:metadata.uid)
      POD_UUID:                 (v1:metadata.uid)
      NODE_NAME:                (v1:spec.nodeName)
      POD_INDEX:               0
      jobUUID:                 702a48b2-48c9-4ca5-9e08-363024eab802
      JOB_UUID:                702a48b2-48c9-4ca5-9e08-363024eab802
      jobName:                 ssd-inference-2
      JOB_NAME:                ssd-inference-2
      NVIDIA_VISIBLE_DEVICES:  <set to the key 'RUNAI-VISIBLE-DEVICES' of config map 'ssd-inference-2-dgk4m8z-runai-sh-gpu'>  Optional: false
      RUNAI_NUM_OF_GPUS:       <set to the key 'RUNAI_NUM_OF_GPUS' of config map 'ssd-inference-2-dgk4m8z-runai-sh-gpu'>      Optional: false
    Mounts:
      /etc/ld.so.preload from ssd-inference-2-dgk4m8z-runai-sh-gpu-vol (ro,path="ld.so.preload-key")
      /etc/runai.d/memory from ssd-inference-2-dgk4m8z-runai-sh-gpu-vol (ro,path="config")
      /etc/runai.d/pod_uuid from ssd-inference-2-dgk4m8z-runai-sh-gpu-vol (ro,path="pod-uuid")
      /runai/shared from runai-shared-directory (ro)
      /storage/ from storage-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-t9cnx (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  storage-volume:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  benchmarking-bert-dataset
    ReadOnly:   false
  kube-api-access-t9cnx:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
    ConfigMapName:           openshift-service-ca.crt
    ConfigMapOptional:       <nil>
  runai-shared-directory:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/runai/shared
    HostPathType:  DirectoryOrCreate
  ssd-inference-2-dgk4m8z-runai-sh-gpu-vol:
    Type:        ConfigMap (a volume populated by a ConfigMap)
    Name:        ssd-inference-2-dgk4m8z-runai-sh-gpu
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  nvidia.com/gpu.present=true
Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule op=Exists
                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason          Age   From             Message
  ----    ------          ----  ----             -------
  Normal  Scheduled       15m   runai-scheduler  Successfully assigned matrix-benchmarking/ssd-inference-2-0-0 to perfdgx2.perf.lab.eng.bos.redhat.com
  Normal  AddedInterface  15m   multus           Add eth0 [10.128.1.4/23] from openshift-sdn
  Normal  Pulled          15m   kubelet          Container image "quay.io/openshift-psap/nvidiadl-ssd-training-benchmark:ssd" already present on machine
  Normal  Created         15m   kubelet          Created container ctr
  Normal  Started         15m   kubelet          Started container ctr
